C:\CS\spark-3.2.1-bin-hadoop3.2\bin\spark-submit --master spark://localhost:7077 --deploy-mode client --driver-memory 12g --driver-cores 1 --executor-memory 5G --executor-cores 1 --total-executor-cores 2 C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Notebook\wo.py > C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Logs\Log_Notebook_Execute\wo_log.txt


C:\CS\spark-3.2.1-bin-hadoop3.2\bin\spark-submit --master spark://localhost:7077 --deploy-mode client --driver-memory 12g --driver-cores 1 --executor-memory 5G --executor-cores 1 --total-executor-cores 2 C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Notebook\wostatus.py > C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Logs\Log_Notebook_Execute\wostatus_log.txt


python C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Code\Notebook_Generator.py > C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Logs\Log_Notebook_Generator\Log_Notebook_Generator.txt

cd C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main

df_wostatus=spark.read.parquet("C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Output_DL_SZ\DL_WOSTATUS")
df_wostatus.printSchema()
df_wostatus.show(truncate=False)


df_wo=spark.read.parquet("C:\CS-PEROSNAL\Translab\Work\Data_Platform\Platform_data_ingestion_tracks-main\Output_DL_SZ\DL_WO")
df_wo.printSchema()
df_wo.show(truncate=False)